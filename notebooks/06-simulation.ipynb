{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2hsl_fn(x):\n",
    "    return colorsys.rgb_to_hls(*x)\n",
    "\n",
    "\n",
    "def rgb2hsl(arr):\n",
    "    w, h, d = arr.shape\n",
    "    assert d == 3\n",
    "    return np.apply_along_axis(rgb2hsl_fn, 1, arr.reshape(-1, 3)).reshape(w, h, 3)\n",
    "\n",
    "\n",
    "def hsl2rgb_fn(x):\n",
    "    return colorsys.hls_to_rgb(*x)\n",
    "\n",
    "\n",
    "def hsl2rgb(arr):\n",
    "    w, h, d = arr.shape\n",
    "    assert d == 3\n",
    "    return np.apply_along_axis(hsl2rgb_fn, 1, arr.reshape(-1, 3)).reshape(w, h, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Images and Survival Data\n",
    "\n",
    "Generate images with black square of different hue determining the risk score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator:\n",
    "    def __init__(self, img_size = (28, 28)) -> None:\n",
    "        self.img_size = img_size\n",
    "        self.length = 10\n",
    "        self.seed = 34734\n",
    "\n",
    "    def _set_random_rectangle(self, img: np.ndarray, color: float, random: np.random.RandomState) -> np.ndarray:\n",
    "        x = random.randint(self.length, self.img_size[0])\n",
    "        y = random.randint(self.img_size[1] - self.length)\n",
    "\n",
    "        img[x - self.length : x, y : y + self.length, :] = color\n",
    "        return img\n",
    "\n",
    "    def make_images(self, num_obs: int) -> Iterable[Tuple[np.ndarray, float]]:\n",
    "        random = np.random.RandomState(self.seed)\n",
    "\n",
    "        n_hues = 100\n",
    "        min_hue = 1\n",
    "        hue_increment = (360 - min_hue) / n_hues\n",
    "        hue_values = min_hue + np.arange(n_hues) * hue_increment\n",
    "\n",
    "        h_idx = random.randint(n_hues, size=num_obs)\n",
    "        color_h = hue_values[h_idx]\n",
    "\n",
    "        for h_channel in color_h:\n",
    "            color_rgb = colorsys.hls_to_rgb(h_channel / 360, 50 / 100, 100 / 100)\n",
    "\n",
    "            img = np.zeros(self.img_size + (3,), dtype=np.float32)\n",
    "            img = self._set_random_rectangle(img, color_rgb, random)\n",
    "\n",
    "            yield img, h_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hue_to_risk_score(hue: np.ndarray) -> np.ndarray:\n",
    "    min_l = np.min(hue)\n",
    "    max_l = np.max(hue)\n",
    "\n",
    "    unit_scaled = (hue + min_l) / (max_l - min_l)\n",
    "    # rescale to make differences between risk groups larger\n",
    "    rescale_factor = np.sqrt(2) * np.pi\n",
    "    return unit_scaled * rescale_factor\n",
    "\n",
    "\n",
    "class SurvivalGenerator:\n",
    "    def __init__(self, mean_survival_time: float = 20.0) -> None:\n",
    "        self.mean_survival_time = mean_survival_time\n",
    "        self.seed = 34734\n",
    "        self.quantile_censored = 0.925  # determines the amount of censoring\n",
    "\n",
    "    def make_survival_time(self, riskscores: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        random = np.random.RandomState(self.seed)\n",
    "\n",
    "        baseline_hazard = 1.0 / self.mean_survival_time\n",
    "        scale = baseline_hazard * np.exp(riskscores)\n",
    "        u = random.uniform(low=0, high=1, size=riskscores.shape[0])\n",
    "        t = -np.log(u) / scale\n",
    "\n",
    "        # generate time of censoring\n",
    "        qt = np.quantile(t, self.quantile_censored)\n",
    "        c = random.uniform(low=t.min(), high=qt)\n",
    "\n",
    "        observed_event = t <= c\n",
    "        observed_time = np.where(observed_event, t, c)\n",
    "        return observed_time, observed_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAK0lEQVR4nGNgGAWjYBSMghEHGHFJ/GeowqutDY8sE/nuGTV01NChbegIBwCcEwIUM9p+zAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF294181F90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALklEQVR4nGNgGAVDAjASkP9/Ga9uXazCTOS6Bh8YNXTU0KFg6CgYBaNgFFANAAB9AAIU+3y93QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF294199110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALklEQVR4nGNgGAWjgKqAkRhF/0/hNcIMXYSJXNfgA6OGjho6FAwdBaNgFAx6AAARRQIUTySoRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF294199190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALElEQVR4nGNgGAUjFzASkP8vg1f3E6zCTOS6Bh8YNXTU0KFg6CgYBaNgZAIAtzACFIbFakQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF294199210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALUlEQVR4nGNgGAWjYBSMglEwaAEjhPrP0IlXUTlJhjKR755RQ0cNHdqG0gQAAGEoAhR+9dzUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF294199290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALElEQVR4nGNgGCqAkRxN/9vxGlnJRJ5b8INRQ0cNHQqGjoJRMApGwSigDgAAWyMCFHkGijwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF294199390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALUlEQVR4nGNgGAWjYIQCRmTO9f/4lGoy4pNFBkzkumbU0FFDh7qho2AUjFgAAOIPAhQilwREAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF294199410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALElEQVR4nGNgGAWjYBSMghEHGLGK/meIxqtnKX5Dmch3z6iho4YObUNHOAAAnnECFILHSlQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF294199490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALElEQVR4nGNgGAXUBowovP/aeNVeJdJQJnJdM2roqKFD3dBRMApGwSgY3AAAPa4CFIu94qAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF294199510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALElEQVR4nGNgGAUjFzASVsLxH5/sDywmMJHrGnxg1NBRQ4eCoaNgFIyCkQkArtgCFEA8w10AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF294199310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_gen = ImageGenerator()\n",
    "images = []\n",
    "hues = []\n",
    "for arr, hue in img_gen.make_images(10000):\n",
    "    img = Image.fromarray((arr * 255).astype(np.uint8), mode=\"RGB\")\n",
    "    images.append(img)\n",
    "    hues.append(hue)\n",
    "\n",
    "for img in images[:10]:\n",
    "    display(img)\n",
    "\n",
    "del arr, hue, img, img_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of events: 0.4918\n"
     ]
    }
   ],
   "source": [
    "risk_scores = hue_to_risk_score(hues)\n",
    "\n",
    "surv_gen = SurvivalGenerator()\n",
    "surv_time, surv_status = surv_gen.make_survival_time(risk_scores)\n",
    "\n",
    "print(\"Percentage of events:\", surv_status.mean())\n",
    "\n",
    "del surv_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot overall survival function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "\n",
    "x, y = kaplan_meier_estimator(surv_status, surv_time)\n",
    "plt.step(x, y, where=\"post\")\n",
    "plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance with true risk scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_ipcw\n",
    "from sksurv.util import Surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7867546831763486, 29017135, 7749011, 318033, 0)\n"
     ]
    }
   ],
   "source": [
    "y = Surv.from_arrays(event=surv_status, time=surv_time)\n",
    "cindex_known = concordance_index_ipcw(y, y, risk_scores)\n",
    "print(cindex_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.467884389654714"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_scores.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from losses import CoxphLoss\n",
    "from models import MyCNN\n",
    "from surv_data import cox_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationData(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self._image_transform = transforms.ToTensor()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, event, time = self.data[index]\n",
    "        return self._image_transform(img), torch.tensor([event], dtype=torch.int8), torch.tensor(time, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    @property\n",
    "    def event(self):\n",
    "        return np.array([d[1] for d in self.data])\n",
    "\n",
    "    @property\n",
    "    def time(self):\n",
    "        return np.array([d[2] for d in self.data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(np.arange(len(images)), stratify=surv_status, test_size=0.2, random_state=0)\n",
    "\n",
    "train_data = SimulationData([(images[i], surv_status[i], surv_time[i]) for i in train_idx])\n",
    "test_data = SimulationData([(images[i], surv_status[i], surv_time[i]) for i in test_idx])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    collate_fn=cox_collate_fn,\n",
    "    pin_memory=True,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    collate_fn=cox_collate_fn,\n",
    "    pin_memory=True,\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNN(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_relu): ReLU()\n",
      "  (conv1_s): Conv2d(6, 6, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2_relu): ReLU()\n",
      "  (conv2_s): Conv2d(16, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (flatten): Flatten()\n",
      "  (dense1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (dense1_relu): ReLU()\n",
      "  (dense2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (dense2_relu): ReLU()\n",
      "  (dense3): Linear(in_features=84, out_features=1, bias=False)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3c72f55a4b4ad79e4814c96b289827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = MyCNN(1)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = CoxphLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 60, 95], gamma=0.2)\n",
    "model.train()\n",
    "\n",
    "pbar = tqdm(range(100), total=100)\n",
    "for epoch in pbar:\n",
    "    mean_loss = 0.0\n",
    "    for batch_img, batch_event, batch_time, batch_riskset in train_loader:\n",
    "        batch_img = batch_img.to(device)\n",
    "        batch_event = batch_event.to(device)\n",
    "        batch_riskset = batch_riskset.to(device)\n",
    "\n",
    "        logits = model(batch_img)\n",
    "        loss = criterion(logits, batch_event, batch_riskset)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        mean_loss += loss.item()\n",
    "    mean_loss /= len(train_loader)\n",
    "    pbar.set_postfix({\"loss\": mean_loss})\n",
    "    pbar.update()\n",
    "\n",
    "del batch_img, batch_event, batch_time, batch_riskset, pbar, criterion, loss, logits, mean_loss, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "\n",
    "pred_risk_scores = []\n",
    "with torch.no_grad():\n",
    "    for batch_img, batch_event, batch_time, batch_riskset in test_loader:\n",
    "        batch_img = batch_img.to(device)\n",
    "\n",
    "        logits = model(batch_img)\n",
    "        pred_risk_scores.append(logits.squeeze(1).detach().cpu().numpy())\n",
    "\n",
    "pred_risk_scores = np.concatenate(pred_risk_scores)\n",
    "\n",
    "del batch_img, batch_event, batch_time, batch_riskset, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare performance of CNN-predicted risk scores to performance on ground truth risk scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7759360379673449 0.7867546831763486\n"
     ]
    }
   ],
   "source": [
    "test_y = Surv.from_arrays(event=test_loader.dataset.event, time=test_loader.dataset.time)\n",
    "cindex_pred = concordance_index_ipcw(y, test_y, pred_risk_scores)\n",
    "print(cindex_pred[0], cindex_known[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The baseline is an all black image (zeros).**\n",
    "\n",
    "Compute the difference we are going to explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_loader = DataLoader(\n",
    "    [test_data[i] for i in range(5)],  # take first 5 samples of test data\n",
    "    collate_fn=cox_collate_fn,\n",
    "    pin_memory=True,\n",
    "    batch_size=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "with torch.no_grad():\n",
    "    baseline = torch.zeros(1, 3, 28, 28, device=device)\n",
    "    baseline_pred = model(baseline).squeeze().detach().cpu().numpy()\n",
    "\n",
    "# the difference SV explains: prediction(true image) - prediction(baseline_image)\n",
    "explain_delta = pred_risk_scores[:explain_loader.batch_size] - baseline_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Value Sampling\n",
    "\n",
    "> E. Štrumbelj and I. Kononenko, “Explaining prediction models and individual predictions with feature contributions,” Knowl. Inf. Syst., vol. 41, no. 3, pp. 647–665, Dec. 2014. [10.1007/s10115-013-0679-x](https://doi.org/10.1007/s10115-013-0679-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_sv_sampling(\n",
    "    model: nn.Module,\n",
    "    img_height: int,\n",
    "    img_width: int,\n",
    "    explain_loader: DataLoader,\n",
    "    n_steps: int = 1000\n",
    ") -> np.ndarray:\n",
    "    batch_size = explain_loader.batch_size\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    n_players =  img_height * img_width\n",
    "    pbar = tqdm(total=n_steps * n_players)\n",
    "    with torch.no_grad():\n",
    "        baseline = torch.zeros(1, 3, img_height, img_width, device=device).expand(\n",
    "            batch_size, -1, -1, -1)\n",
    "\n",
    "        # only use the first batch\n",
    "        batch = next(iter(explain_loader))\n",
    "        img = batch[0].to(device)\n",
    "\n",
    "        attributions = np.zeros(\n",
    "            (batch_size, img_height, img_width, 1), dtype=float\n",
    "        )\n",
    "        for _ in range(n_steps):\n",
    "            perm = torch.randperm(n_players, device=device)\n",
    "            img_in = baseline.repeat(2, 1, 1, 1)\n",
    "            for end in range(n_players):\n",
    "                idx = perm[end]\n",
    "                # img_in already includes real values that come before `j` in `perm`\n",
    "                # only need to add current point to first half\n",
    "                i, j = np.unravel_index(idx.detach().cpu().numpy(), (img_height, img_width))\n",
    "                img_in[:batch_size, :, i, j] = img[..., i, j]\n",
    "\n",
    "                pred = model(img_in)\n",
    "                pred_w_i, pred_wo_i = torch.chunk(pred, 2)\n",
    "                delta = pred_w_i - pred_wo_i\n",
    "\n",
    "                attributions[:, i, j] += delta.detach().cpu().numpy()\n",
    "\n",
    "                # add current point to second half, such that both parts are equal\n",
    "                img_in[batch_size:, :, i, j] = img[..., i, j]\n",
    "\n",
    "                pbar.update()\n",
    "\n",
    "        attributions /= n_steps\n",
    "\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "\n",
    "def pil_image_iterator(data_loader):\n",
    "    with torch.no_grad():\n",
    "        convert_img = transforms.ToPILImage()\n",
    "        for batch_img, batch_event, batch_time, batch_riskset in data_loader:\n",
    "            for i in range(data_loader.batch_size):\n",
    "                img = convert_img(batch_img[i])\n",
    "                yield img\n",
    "\n",
    "\n",
    "def attributions_to_image(attributions):\n",
    "    assert attributions.ndim == 3\n",
    "    # map SV to RGBA\n",
    "    mapper = ScalarMappable(\n",
    "        Normalize(vmin=attributions.min(), vmax=attributions.max()),\n",
    "        cmap=\"inferno\"\n",
    "    )\n",
    "    images = tuple(\n",
    "        Image.fromarray(mapper.to_rgba(attr, bytes=True), mode=\"RGBA\")\n",
    "        for attr in attributions\n",
    "    )\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠⚠⚠ **THIS WILL TAKE TIME** ⚠⚠⚠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f7727fd17742a6baca5c72c5dae437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=784000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sv_sampling = explain_sv_sampling(model, 28, 28, explain_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALUlEQVR4nGNgGAUjFzBCqEKG/3gU9cOUEQmYyHfPqKGjhg5tQ0fBKBgFIxMAAPImAhSJb3XUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF21D71BED0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABm0lEQVR4nO3Vy2oTARjF8f/c0rk4yZiZxMTYamMo9dJa6spXEN/AR3Dt2icTBV1IKQgSVCQkVRtrpq1p5paEubkScZ2hC5mzOrsffN/iCOOnezmXGPEysRL8P0D5T7E2xwwOdjHNgNcf79PUQ96f27S1BUNfp2tGpLnAk4eHxYDRpI4kZghCzp3GhKoRoMkx151TtmcW1+wzorm2EvYPqDozWmKOqCSsqQvyXMSs+hhXPaqWhyBkZJm0Mvj3h5lAGssYt06QKgn17SMUdcmV3jGqGWLvf8FqnBcHytUQvTElDVU0+4J0XkG3ZySegWKG5ImEVveKA7NlhTjUkJ2QZK6iND2SSEWxffJUQqrFZHGBJ80TEVFKCT930G+4uO/uojan+J82UGoBQb+DUguLA71vLSbDDfTbJ4ze7OPcGzI62MHc+crPD1to6y7TwXpxoNU7xg8MfrzdpdX9Tv/lI5y2y/jVHs7mmF/9LmtGVByobC252RvReTZl4Rk8eDFgdlan/TwmPLVoPD7iwrVXBoVyD0uwBEuwBFfObzkSlJ8age/6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=28x28 at 0x7FF21D71BA90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completness Δ = 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALklEQVR4nGNgGAWjYBSMgsEMGIlR9D8erxEL0UWYyHUNPjBq6KihQ8HQUUB9AAAyRwIULOS2dQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF21DCDF3D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABtklEQVR4nO3Wz0/TAADF8S8b60SHsEHXzBIGCtPAFPwZMUFM9KBePHrwT+Dif+C/wMWbISHhoGdJSCAo04RgOJiZiNMx68R2bbZ2bMqUdWX+BTssaTAmffeXT97tdaiPJpscYXxHiXmgB3qgB3rgPwKjt7bJ7JwhGKqRSk/QFa6SSk8Qkkyeb07RHSuxZ/W6Bzbr8EqLcej4WDd6KOQGWVROUP4hkakGqGoi67mEe2BxY4y+YAMtP4DTBNUU6RX8fFdlag0w9CjnRcM9UC9IrOl+bDtAer/CceGAt3aGgN9h6c9rRLHEfCbuHhgfVZC7/OyYURLHTrJbCRN3hlCsPi5xA7UQY0qsuQfqeZnl35841V1hw84xFDZ5Z79kOGKSOnhBf9jiWb7Rst/ZLhjpN7nANB+KDS77BL6Yv7gSuE/OOmQm+JBdo8jscOsdbS8smxE+ojAY+slqfY2kpLFVX+La6SybzgrJ5DZz3+rugXJCYUYYAeBe8DZ7+yGuCw/IqgNMd96lpEk8Odv6CLYNZtNjLFhPGY8rfLbLXLz6Ht1ncPPOG3QqyOe+8jhbatnv8H7pfw/+BRzAooSfOcB0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=28x28 at 0x7FF21DB68290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completness Δ = 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALklEQVR4nGNgGAVDAjCi8UUZ/uNR/RpDPVbARL57Rg0dNXRoGzoKRsEoGAVUAwCFvAIUtrEydgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF21DC6C390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABkUlEQVR4nO3Vz04TURTH8e+90/lTSp1paLGpFqVEiZKoiexc+AQ8gQ+qO+OGuDNuNBJKUqAJ0HYYW2i9M9x7XZuMCyaVxGTO8mw++Z1zkiOG715Z7rDkXWIl+E+qktdMlYcxktF4jWsVoK0k0xKLIDMOAKG/YHvraDng5x/PSI2kP6uhLSTpn4M4W1h2Irs8cG/vPV43YfBhl87LAy6+9Wg8OCc+bdPcHJKc3Ke+HjOPw1uDuTsU0pINQ8JWjFEuQW0OwuIHCq+ZoLWD42e3xv4Kuq0p3hsf6Rj8xxO8qiJoxwThDKeR0nxyTPXFuBCYfzTnIWKkcGsCPV4BQF9VsdqBqkQIg4kLefkJ/UcJ7ttV5pMQpGEWhxjtoK5WuBkEZLMa3IhCYG5CNYhIPkXc64z4edgl6lwwPW4T1K+xRlBZXaDO1gqBuQm/778miSO+7O8CcPj1OdYKTo82SC/rTPoPQZjlgRu9AR/7T9nsnjCdRPR2DshSl9b6CFkxpL985uNGIVCU76kES7AES/D/A38DYi2W1vtSi84AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=28x28 at 0x7FF21DB68B90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completness Δ = 2.0816681711721685e-17\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALklEQVR4nGNgoAFghNL3/uNTpcSITxYDMJHrmlFDRw0d6oaOglEwCkbBKBjEAABvswIURUWjHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF21DCDF050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABiklEQVR4nO3Uu27TcBTH8e/fjp0Y35IQ2hJaRai0FRUqF3XkOVh4Sl6AEQYmqJAoKgkealpHkRPfEt+ZgA0J1YIBn+lM56PfOdIRly+f1PzFkn40QlRInQJ74lIWMvrIpyol7InLyreROgVxqDcHdq2Y0Lcpkh5F0SENdbJMpcpUHG+baGkRRkZzoOfcI0504vkQbz4iCQyml7sE7h3iXOXMuc+ri4PmwPHRDNcfoGgbZKlCSBWyqLD3rvi4tBnpEXUD1/6V8MseW2aArOZUtaB/d44QNbKW8nzniqEZsMik3836M3D78CtR2qPTy+hbIYgao7tBOQEn6GNYIZZy84g/wdn7h2hKRnR9myA0WPsWfmKwfnOL/cGCKDApm1zp/ukZ777tYo49JKlC1VKyUkY7XZEWCuMHDqrUYMJPb59hKjmhu8W5t0O27nK+HJB+0FjnCnnSY1OK5sCTF6+RRc3weMrTyQxtEHA8WNA9XPH44DP9R1MuwpsnFP/stbVgC7ZgC7ZgC/7H4HfPMJyHoLOPlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=28x28 at 0x7FF21DB5FA50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completness Δ = 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALklEQVR4nGNgGCqAkViF5//jkzVEMYeJXNfgA6OGjho6FAwdBaNgFIyCUUAdAAB7kwIU6YKeCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF21DCDF590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABqElEQVR4nO3U3WrTcBjH8W9eliZZklVSqN1oV9qh65AxqLBNPdOLEPTI3ZDgiRfgtQzF7UCsjFWLtXPOpZ19W1Kb9Z94AQ6EEnYg+Z1/+Rw88Einz7ZibnDyTWIA6jyR9fIRi+4O0as9pBWDYN/GqJ4jBjqDZgl/aBPHEqYVJAO+3hY8Xn1Ds/uUJzvvaDQ2KBz3aP1cRpUjPl643M0OqNeOkgH3uwphVKVoTphemnQDi8zCFRl1xmBi4E1VLrwc9drf7Vw3fLH2i+f332OoM/IPG1Rdj80HB5jalN17DTazl+zVD69t5wK/jh3iWOK2NYKNIo49BqBcOkG3fX4LhQ/tSnLg7koHSYo5HS0hDfvIcoRW6NPruogrlbzpU1v+nhz49kcRMVMwFmaIYoVgYhCNdSzLZ2n9G7IU0/byyYFZLWQ6zdAcOiifj2h5BWIhc/DlDkEnTygUttaPkwNFJKNpIVV7DHqGsttF1kPWcucsls+4ZQSMBk5y4Ha5Ra50RigURDOkN3bw2wU6/Rz9TxV6vkXjZPXaVvrvf2kKpmAKpmAKpuC/9wdo95sSZ0otCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=28x28 at 0x7FF21DB5F990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completness Δ = 0.0\n"
     ]
    }
   ],
   "source": [
    "for sv, sv_image, input_image, delta in zip(\n",
    "    sv_sampling.squeeze(-1),\n",
    "    attributions_to_image(sv_sampling.squeeze(-1)),\n",
    "    pil_image_iterator(explain_loader),\n",
    "    explain_delta\n",
    "):\n",
    "    display(input_image)\n",
    "    display(sv_image)\n",
    "    print(\"Completness Δ =\", np.absolute(sv.sum() - delta))\n",
    "\n",
    "del sv, sv_image, input_image, delta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients\n",
    "\n",
    "> M. Sundararajan, A. Taly, and Q. Yan, “Axiomatic Attribution for Deep Networks,” in Proceedings of the 34th International Conference on Machine Learning, 2017, pp. 3319--3328. http://arxiv.org/abs/1703.01365\n",
    "\n",
    "$$\n",
    "(x_i - x_i^\\prime) \\cdot \\frac{1}{m} \\sum_{k=1}^m \\frac{ \\partial F(x^\\prime + \\frac{k}{m} (x - x^\\prime)) }\n",
    "{ \\partial x_i }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_gradients(\n",
    "    model: nn.Module,\n",
    "    explain_loader: DataLoader,\n",
    "    n_steps: int = 100,\n",
    "    output_idx: int = 0\n",
    ") -> np.ndarray:\n",
    "    model = model.eval()\n",
    "    batch_size = explain_loader.batch_size\n",
    "\n",
    "    baseline = torch.zeros(1, 3, 28, 28, device=device)\n",
    "    alphas = torch.linspace(0, 1, n_steps, device=device).view(-1, 1, 1, 1)\n",
    "\n",
    "    # only use the first batch\n",
    "    batch = next(iter(explain_loader))\n",
    "    img = batch[0].to(device)\n",
    "\n",
    "    inputs = tuple(\n",
    "        (xp.unsqueeze(dim=0) + (x - xp).unsqueeze(dim=0) * alphas).requires_grad_()  # shape = n_steps, 3, 28, 28\n",
    "        for x, xp in zip(img, baseline.expand_as(img))\n",
    "    )\n",
    "\n",
    "    with torch.autograd.set_grad_enabled(True):\n",
    "        outputs = model(torch.cat(inputs, dim=0))\n",
    "        # Computes and returns the sum of gradients of outputs w.r.t. the inputs\n",
    "        grads = torch.autograd.grad(torch.unbind(outputs[:, output_idx]), inputs)\n",
    "\n",
    "    assert len(grads) == batch_size\n",
    "    assert grads[0].size()[0] == n_steps\n",
    "\n",
    "    img_baseline_diff = img - baseline  # shape (batch_size, 3, 28, 28)\n",
    "    # average over alphas\n",
    "    attributions = torch.stack([grad.mean(dim=0) for grad in grads])\n",
    "    attributions *= img_baseline_diff\n",
    "    attributions = attributions.detach().cpu().numpy()\n",
    "    \n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_attributions = integrated_gradients(model, explain_loader, n_steps=10000)\n",
    "ig_attributions = ig_attributions.sum(axis=1)  # sum over channel dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALUlEQVR4nGNgGAUjFzBCqEKG/3gU9cOUEQmYyHfPqKGjhg5tQ0fBKBgFIxMAAPImAhSJb3XUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF21454FB10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABrklEQVR4nO3Uv2sTYRjA8e97ud+pJOSStlLRpi5axElKBQcRBwd3cXJzEAcR/wQX/xMH9wpCKbhqxKHWIRQpRYWa9BIud7n37t7XobbR+UqGmmd6hhc+z8P7PI8In13UTDGMaWIz8GyA5nFi1yP2O1fJMovOXhsF/Exc6nbGUFq03BTTUNy/u3k6YJE4+HMxlpuybku8akLYr9No9khin1qrTza2S2EA4ngPnWCI4aXozERYOSq1EIZGONnRw4omD33k4blS4MkfaiWQvRqVpQyVOJjNMSq1MJp/KjvvYHiyFPYPaHgSeyFEjxTmfIyWYAYR5PoIdVwq8/npgRQGeX8OEbgUhzaiKiiGLtgV9ECBVuhBaW8Cyl6NPPLov72AUZV8eX0LYRX8ereCsGG05SP88mf3BBwd1NnfuUzjQUR34yarTz6zu3WDxmMIP7RxHwbEOwulwcmUtkI+btzm+noHqxbx/dMVFq91KWIXb22I/pEifM1oe7EUOBmaO21Wlr+hX9xjsLvEpTdPOfi6jPvqJdH7gOTRc8bdoGR/f3U4rTj7x3sGzsAZ+B+CvwHHXpjGx8zRwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=28x28 at 0x7FF21454FA90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completness Δ = 0.000495702\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALklEQVR4nGNgGAWjYBSMgsEMGIlR9D8erxEL0UWYyHUNPjBq6KihQ8HQUUB9AAAyRwIULOS2dQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF21DB68ED0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABxElEQVR4nO3WvU8TcRzH8XfrAW1pKzXXQqti9QxcDFWE+BQNxoeBxDC66+TiQOKok4sbIaz6J7AICSGRRIiFEB5itMWg2FLSXqk9WmmhPJz06l9wQ5MLxuR++zuvfIZv8rNtD7bXOMZnP07MAi3QAi3QAv8RqK6f4ctCD/qRwHpcBmBl+Qp2QSe+1I3zsZeq1mAeGJDSRLMhBOcB72IymVWJ4a9hCqkQs9nTKEPNvBx9ZB6YinfQ699C+XaRU406pYqboNNGXhX5rQkc7Dt4dnnVPDDYrvBBaaVFLDJfqOLzlJnYSeE7WWJEncDlrvA2Jhv2Qr1gPhNE9u6TSFwg3NzARr6VLnuAH4qLAUcPuVyS+21Fw77uhf7QL6Y2nUhSksVKkbOiyuThOFJblkltGr9Y4PWabtjXvVBwHCJ5IPr5KnJjCyn1iD5BZm1zm9v2LnJqmhfnmwz7uhd6ImnSezbuXl9kRVPp7vzOQm2Oa5EYP8kSubnMq42MeaAavcSb/k+Ut3zc8wbY23XR39RHMS8SrgWZ/XiH0V4T79D/pMStMZFzTxNoOoQfLFH+U6VjMIlbOMHD5++5MTNl2Nusf+l/D/4FuUebukBvaiYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=28x28 at 0x7FF26E475290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completness Δ = 0.0013535023\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALklEQVR4nGNgGAVDAjCi8UUZ/uNR/RpDPVbARL57Rg0dNXRoGzoKRsEoGAVUAwCFvAIUtrEydgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF21DB5F510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABn0lEQVR4nO3Uv08TcRzG8ff3vvejZ1sr5CxaC4qULiRGiZgQEif+F1f/Iv8E46KTk3FQQ6QsoBRog4nRtpSWu3L07r49R5dbbK4M5p7xWV7DJ89HDF4uxVxjtOvEMnAm0ZNK95cDwHBQot1dwNZD/MjA1kO8wOKGGTCfd1l5dJAO+K6xzijSiWNBe2TgWIreWHLXjrgIJf2xYLUYTgWKpFnkKmfIckT/wwpzG0f4zQWs2wOCfpHcUg/3YBE9FxBPxD+DyTdUGvEQSvVT4pHEKHkA6AUf8WCeWP3tUgHloiLa3kJ5NuJJBaErZHmMZoVgmpS2TjGe2umBwbc82tvPmOsK4bnIwhgmoNkhYbUG4QT8y/RAc0MgNu/TfXMPXI+zr6sEP25yeXIH49NHVNeECz89MG4POX8lcDa/Ex5bzK21GP10sMrnkLeQNR3120wPbL1/hhAx+6+fI/NX9Bp1CtUO/f2HEClUUyGXp/KSweXtLzQPa6y92ME7quI8PmTYqlCsdPD3btFp1LnaLUwFJu5wlvn/n3cGZmAGZuDs8weEL5guaGbzNQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=28x28 at 0x7FF26E475E10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completness Δ = 0.00046651438\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALklEQVR4nGNgoAFghNL3/uNTpcSITxYDMJHrmlFDRw0d6oaOglEwCkbBKBjEAABvswIURUWjHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF21DB68910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABqElEQVR4nO3UzWoTYQCF4XfS+SZph2RiXEiYkjQptlYrBQUJWhVFRERQXLj3DroRvAQvw6WXUHBRhCwUtVohYP2pYzFNa2OSNpPMz5eZcVVvIIMunLM6u4ezOUpvpRTxF5M6KsOOQeALtLzNYL+AkooYdgzUKZe2ZRKOVPa+lscG1aMyVThg890iC/p7Bn2dMEjhuWm0Xx59Ows/QEt7Y4N/FlqNOQB2NytstUykFLz8Mk8gVXZ7eaQUrDXOxgfOX3nDqlWhUNzHDyZwnQxBpJDO2TgjgRCS6exhfODn+jluzXzDd9JMCsnsjVcIJUS/5mIaXcr31tmxs/GBC/frrG3PkC22OZHvEDoahUkHMhmOGQeQUijlevGBG8+uc3vuI983TtEf6kSjCbyRCt0uvq9BGDGUWnzg0so6Tz+cYfbyW8xiC1FxOK7b+Es1zJMW8nyNotGND6w/ucSdcpPepxJb2yWifkjr0EBtN/lpTaN29hh4mfjA5Ucv2LFzGNUmF+8+h8UqVy+8xj19k+rDBiw/pvZgdWxQ+WfXloAJmIAJmIAJ+B+DvwGkNJveaRgjcwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=28x28 at 0x7FF26E475E50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completness Δ = 0.0006260872\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAALklEQVR4nGNgGCqAkViF5//jkzVEMYeJXNfgA6OGjho6FAwdBaNgFIyCUUAdAAB7kwIU6YKeCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FF21DB68150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABrUlEQVR4nO3Uz0uacQDH8bfPY/6ojMzVzExJTWqDWEtHbbKiw66xvEWHYOy2INgfM+gPiE6xTju1INhYMKTLmI/OtDK1ovkjfzx75mP7BzqNL52ez/3N6/YxVTZ8t9zjpPvE/hu0vA1heTOGrnXR8+SCWnGQvw07APlkkKusl8S3iDhwZfYRm68n2d1fQDt2kMwG+NPo5uDgBTabys8zP87eujjw480H9koymbqden6IsmpHyQRwWFWqtT4Ge29IXbrFgZ9nl4j7Wqi6CWf0F5ou82zxC9nKABPPE3TJbZbXt8WB++ceov5jwn0t2rE55saTWN1lXk0nsPirjI6dUj4MiAPXot9RiiOcN22YS6d0OhKmkIuTMy9IoGtmnEsVceBXZZKnYYWgo0FrJo7Lc0mnf4DwRAp9aor+UJ72kSoOnB7NUSy50XQZa3qP68IQUr1GLh1AzijUToaRFr3iwMLvB3g9BWLBFOboe3yxI5qRZR4vHNJ6GccVSyMV8+LAmUgCTbOQu3Bzu/OOatJP96dNymkftt0tmj8e0pxfvbM1GV9qgAZogAZogAbIP3rUmgsRlc/mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=28x28 at 0x7FF21454F050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completness Δ = 0.0007176399\n"
     ]
    }
   ],
   "source": [
    "for ig, ig_image, input_image, delta in zip(\n",
    "    ig_attributions,\n",
    "    attributions_to_image(ig_attributions),\n",
    "    pil_image_iterator(explain_loader),\n",
    "    explain_delta\n",
    "):\n",
    "    display(input_image)\n",
    "    display(ig_image)\n",
    "    print(\"Completness Δ =\", np.absolute(ig.sum() - delta))\n",
    "    \n",
    "del ig, ig_image, input_image, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 (mesh)",
   "language": "python",
   "name": "python3-mesh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}