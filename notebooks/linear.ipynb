{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pdb\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sksurv.datasets import load_whas500\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Cox PH Model with sksurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "afb=1       0.012764\n",
       "age         0.684880\n",
       "av3=1       0.045116\n",
       "bmi        -0.254596\n",
       "chf=1       0.338557\n",
       "cvd=1      -0.024386\n",
       "diasbp     -0.272298\n",
       "gender=1   -0.142440\n",
       "hr          0.284784\n",
       "los        -0.032106\n",
       "miord=1     0.039950\n",
       "mitype=1   -0.110669\n",
       "sho=1       0.251575\n",
       "sysbp       0.049986\n",
       "Name: sksurv, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "X, y = load_whas500()\n",
    "mask = X.notnull().all(axis=1)\n",
    "X, y = X.loc[mask], y[mask.values]\n",
    "\n",
    "Xe = OneHotEncoder().fit_transform(X)\n",
    "Xt = StandardScaler().fit_transform(Xe)\n",
    "\n",
    "coxph = CoxPHSurvivalAnalysis().fit(Xt, y)\n",
    "coxph_coef = pd.Series(coxph.coef_, index=Xe.columns, name=\"sksurv\")\n",
    "coxph_coef"
   ]
  },
  {
   "source": [
    "## Fit a Cox Model with Pytorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_riskset(time: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute mask that represents each sample's risk set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time : np.ndarray, shape=(n_samples,)\n",
    "        Observed event time sorted in descending order.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    risk_set : np.ndarray, shape=(n_samples, n_samples)\n",
    "        Boolean matrix where the `i`-th row denotes the\n",
    "        risk set of the `i`-th instance, i.e. the indices `j`\n",
    "        for which the observer time `y_j >= y_i`.\n",
    "    \"\"\"\n",
    "    assert time.ndim == 1, \"expected 1D array\"\n",
    "\n",
    "    # sort in descending order\n",
    "    o = np.argsort(-time, kind=\"mergesort\")\n",
    "    n_samples = len(time)\n",
    "    risk_set = np.zeros((n_samples, n_samples), dtype=np.uint8)\n",
    "    for i_org, i_sort in enumerate(o):\n",
    "        ti = time[i_sort]\n",
    "        k = i_org\n",
    "        while k < n_samples and ti == time[o[k]]:\n",
    "            k += 1\n",
    "        risk_set[i_sort, o[:k]] = 1\n",
    "    return risk_set\n",
    "\n",
    "\n",
    "def cox_collate_fn(\n",
    "    batch: List[Any], time_index: Optional[int] = -1, data_collate=default_collate\n",
    ") -> List[torch.Tensor]:\n",
    "    \"\"\"Create risk set from batch.\"\"\"\n",
    "    transposed_data = list(zip(*batch))\n",
    "    y_time = np.array(transposed_data[time_index])\n",
    "\n",
    "    data = []\n",
    "    for b in transposed_data:\n",
    "        bt = data_collate(b)\n",
    "        data.append(bt)\n",
    "\n",
    "    data.append(torch.from_numpy(make_riskset(y_time)))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def safe_normalize(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Normalize risk scores to avoid exp underflowing.\n",
    "\n",
    "    Note that only risk scores relative to each other matter.\n",
    "    If minimum risk score is negative, we shift scores so minimum\n",
    "    is at zero.\n",
    "    \"\"\"\n",
    "    x_min, _ = torch.min(x, dim=0)\n",
    "    c = torch.zeros(x_min.shape, device=x.device)\n",
    "    norm = torch.where(x_min < 0, -x_min, c)\n",
    "    return x + norm\n",
    "\n",
    "\n",
    "def logsumexp_masked(\n",
    "    risk_scores: torch.Tensor, mask: torch.Tensor, dim: int = 0, keepdim: Optional[bool] = None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute logsumexp across `dim` for entries where `mask` is true.\"\"\"\n",
    "    assert risk_scores.dim() == mask.dim(), \"risk_scores and mask must have same rank\"\n",
    "\n",
    "    mask_f = mask.type_as(risk_scores)\n",
    "    risk_scores_masked = risk_scores * mask_f\n",
    "    # for numerical stability, substract the maximum value\n",
    "    # before taking the exponential\n",
    "    amax, _ = torch.max(risk_scores_masked, dim=dim, keepdim=True)\n",
    "    risk_scores_shift = risk_scores_masked - amax\n",
    "\n",
    "    exp_masked = risk_scores_shift.exp() * mask_f\n",
    "    exp_sum = exp_masked.sum(dim, keepdim=True)\n",
    "    output = exp_sum.log() + amax\n",
    "    if not keepdim:\n",
    "        output.squeeze_(dim=dim)\n",
    "    return output\n",
    "\n",
    "\n",
    "class CoxphLoss(nn.Module):\n",
    "    def forward(self, predictions: torch.Tensor, event: torch.Tensor, riskset: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Negative partial log-likelihood of Cox's proportional\n",
    "        hazards model.\n",
    "\n",
    "        Args:\n",
    "            predictions (torch.Tensor):\n",
    "                The predicted outputs. Must be a rank 2 tensor.\n",
    "            event (torch.Tensor):\n",
    "                Binary vector where 1 indicates an event 0 censoring.\n",
    "            riskset (torch.Tensor):\n",
    "                Boolean matrix where the `i`-th row denotes the\n",
    "                risk set of the `i`-th instance, i.e. the indices `j`\n",
    "                for which the observer time `y_j >= y_i`.\n",
    "\n",
    "        Returns:\n",
    "            loss (torch.Tensor):\n",
    "                Scalar loss.\n",
    "\n",
    "        References:\n",
    "            .. [1] Faraggi, D., & Simon, R. (1995).\n",
    "            A neural network model for survival data. Statistics in Medicine,\n",
    "            14(1), 73â€“82. https://doi.org/10.1002/sim.4780140108\n",
    "        \"\"\"\n",
    "        if predictions is None or predictions.dim() != 2:\n",
    "            raise ValueError(\"predictions must be a 2D tensor.\")\n",
    "        if predictions.size()[1] != 1:\n",
    "            raise ValueError(\"last dimension of predictions ({}) must be 1.\".format(predictions.size()[1]))\n",
    "        if event is None:\n",
    "            raise ValueError(\"event must not be None.\")\n",
    "        if predictions.dim() != event.dim():\n",
    "            raise ValueError(\n",
    "                \"Rank of predictions ({}) must equal rank of event ({})\".format(predictions.dim(), event.dim())\n",
    "            )\n",
    "        if event.size()[1] != 1:\n",
    "            raise ValueError(\"last dimension event ({}) must be 1.\".format(event.size()[1]))\n",
    "        if riskset is None:\n",
    "            raise ValueError(\"riskset must not be None.\")\n",
    "\n",
    "        event = event.type_as(predictions)\n",
    "        riskset = riskset.type_as(predictions)\n",
    "        predictions = safe_normalize(predictions)\n",
    "\n",
    "        # move batch dimension to the end so predictions get broadcast\n",
    "        # row-wise when multiplying by riskset\n",
    "        pred_t = predictions.t()\n",
    "\n",
    "        # compute log of sum over risk set for each row\n",
    "        rr = logsumexp_masked(pred_t, riskset, dim=1, keepdim=True)\n",
    "        assert rr.size() == predictions.size()\n",
    "\n",
    "        losses = event * (rr - predictions)\n",
    "        loss = torch.mean(losses)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "source": [
    "Define the dataset and our model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhasDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        X, y = load_whas500()\n",
    "        mask = X.notnull().all(axis=1)\n",
    "        X, y = X.loc[mask], y[mask.values]\n",
    "\n",
    "        Xe = OneHotEncoder().fit_transform(X)\n",
    "        Xt = StandardScaler().fit_transform(Xe).astype(np.float32)\n",
    "        y_event = y[\"fstat\"][:, np.newaxis].astype(np.uint8)\n",
    "        y_time = y[\"lenfol\"].astype(np.float32)\n",
    "\n",
    "        self.n_features = Xt.shape[1]\n",
    "        self.data = list(zip(Xt, y_event, y_time))\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class CoxModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_inputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer = nn.Linear(n_inputs, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "source": [
    "Run training, may take a while."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 2.715545\n",
      "1000 2.2721267\n",
      "2000 2.236773\n",
      "3000 2.2314878\n",
      "4000 2.2305958\n",
      "5000 2.2305293\n",
      "6000 2.2305286\n",
      "7000 2.2305286\n",
      "8000 2.2305286\n",
      "9000 2.2305286\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(25)\n",
    "dev = torch.device(\"cuda\")\n",
    "\n",
    "train_dataset = WhasDataset()\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, collate_fn=cox_collate_fn, batch_size=len(train_dataset)\n",
    ")\n",
    "model = CoxModel(train_dataset.n_features).to(dev)\n",
    "opt = Adam(model.parameters(), lr=5e-4)\n",
    "loss_fn = CoxphLoss()\n",
    "\n",
    "model.train()\n",
    "for i in range(10000):\n",
    "    for x, y_event, y_time, y_riskset in train_loader:\n",
    "        pdb.set_trace()\n",
    "        x = x.to(dev)\n",
    "        y_event = y_event.to(dev)\n",
    "        y_riskset = y_riskset.to(dev)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = model.forward(x)\n",
    "\n",
    "        loss = loss_fn(logits, y_event, y_riskset)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, loss.detach().cpu().numpy())"
   ]
  },
  {
   "source": [
    "Compare Coefficients"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            sksurv   pytorch\n",
       "afb=1     0.012764  0.012764\n",
       "age       0.684880  0.684879\n",
       "av3=1     0.045116  0.045116\n",
       "bmi      -0.254596 -0.254596\n",
       "chf=1     0.338557  0.338557\n",
       "cvd=1    -0.024386 -0.024386\n",
       "diasbp   -0.272298 -0.272298\n",
       "gender=1 -0.142440 -0.142440\n",
       "hr        0.284784  0.284784\n",
       "los      -0.032106 -0.032106\n",
       "miord=1   0.039950  0.039950\n",
       "mitype=1 -0.110669 -0.110669\n",
       "sho=1     0.251575  0.251575\n",
       "sysbp     0.049986  0.049986"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sksurv</th>\n      <th>pytorch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>afb=1</th>\n      <td>0.012764</td>\n      <td>0.012764</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>0.684880</td>\n      <td>0.684879</td>\n    </tr>\n    <tr>\n      <th>av3=1</th>\n      <td>0.045116</td>\n      <td>0.045116</td>\n    </tr>\n    <tr>\n      <th>bmi</th>\n      <td>-0.254596</td>\n      <td>-0.254596</td>\n    </tr>\n    <tr>\n      <th>chf=1</th>\n      <td>0.338557</td>\n      <td>0.338557</td>\n    </tr>\n    <tr>\n      <th>cvd=1</th>\n      <td>-0.024386</td>\n      <td>-0.024386</td>\n    </tr>\n    <tr>\n      <th>diasbp</th>\n      <td>-0.272298</td>\n      <td>-0.272298</td>\n    </tr>\n    <tr>\n      <th>gender=1</th>\n      <td>-0.142440</td>\n      <td>-0.142440</td>\n    </tr>\n    <tr>\n      <th>hr</th>\n      <td>0.284784</td>\n      <td>0.284784</td>\n    </tr>\n    <tr>\n      <th>los</th>\n      <td>-0.032106</td>\n      <td>-0.032106</td>\n    </tr>\n    <tr>\n      <th>miord=1</th>\n      <td>0.039950</td>\n      <td>0.039950</td>\n    </tr>\n    <tr>\n      <th>mitype=1</th>\n      <td>-0.110669</td>\n      <td>-0.110669</td>\n    </tr>\n    <tr>\n      <th>sho=1</th>\n      <td>0.251575</td>\n      <td>0.251575</td>\n    </tr>\n    <tr>\n      <th>sysbp</th>\n      <td>0.049986</td>\n      <td>0.049986</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "torch_coef = pd.Series(\n",
    "    next(model.parameters()).detach().cpu().numpy().squeeze(),\n",
    "    index=Xe.columns, name=\"pytorch\"\n",
    ")\n",
    "pd.concat((coxph_coef, torch_coef), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('deepsurv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "31e6a7e7c664630bbdbe5bf37b39dec676f9054b5ed7698262a301c861c12718"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}